ğŸ©º HealthCare Data Integration & Analytics Pipeline
This project is an end-to-end data integration and analytics pipeline for healthcare data. It processes real-world FDA drug reports, automates ingestion using Python, models the data with dbt, and stores it in Snowflake for scalable analytics. The goal is to simulate how healthcare platforms can clean, organize, and gain insights from complex, semi-structured medical data in an automated fashion.

ğŸ“Œ Problem Statement
In the healthcare domain, regulatory data like FDA reports is often messy, semi-structured (JSON), and underutilized. Stakeholdersâ€”including researchers, public health analysts, and pharma companiesâ€”struggle to derive meaningful insights due to:

Inconsistent data formats (CSV, JSON)

Complex nested structures

No change tracking over time

Lack of modular pipelines to manage ingestion, transformation, and analytics

ğŸ¯ Goal
Build a reliable healthcare data pipeline that:

Ingests FDA drug reports in JSON and CSV formats

Stores and manages structured + semi-structured data in Snowflake

Transforms raw data into analytics-ready tables using dbt

Tracks data changes and enriches insights for healthcare decision-makers

ğŸ“Œ Project Architecture
Data source: FDA adverse event drug report datasets

Local data cleaning and format conversion (CSV & NDJSON)

Python pipeline for automation and Snowflake ingestion

Data modeling using dbt (source â†’ staging â†’ marts)

Future extensions: snapshots, enrichment, and dashboarding

ğŸ” What Business Problems This Solves
âŒ Problem	âœ… Solution
Unstructured FDA data (JSON, CSV)	Python preprocessing + NDJSON formatting
No central store for drug reports	Snowflake-based warehousing (structured + VARIANT support)
Difficulty analyzing side effects by drug/region	dbt models with filters, joins, and regional aggregations
No version control of reports	Plan for dbt Snapshots to track changes
Manual ingestion and loading	Python automation using Snowflake Connector

ğŸ§  Technologies Used
Area	Tool/Tech
Data Ingestion	Python (snowflake-connector-python)
Storage	Snowflake
Modeling	dbt
File Formats	CSV, JSON (NDJSON), VARIANT
CLI Tools	SnowSQL
Automation	Python scripts
Visualization (Planned)	Tableau / Power BI

ğŸ“Š Core Features / Models
Model/File Name	Purpose
drug_listing_fda	Main table for structured CSV report data
json_data_fda	Table for storing raw NDJSON using VARIANT
stg_drug_listing_fda.sql	dbt staging model: cleaned & typed version of the raw data
marts/ (planned)	Business insights: side effects by drug/region
snapshots/ (planned)	Historical tracking of drug safety reports

ğŸ“¥ Data Loading Progress
âœ… CSV Upload to Snowflake

Stage Created: @drug_stage

File Format: CSV with headers

Table: drug_listing_fda

Load Command:

sql
Copy
Edit
COPY INTO drug_listing_fda
FROM @drug_stage/fda_cleaned.csv.gz
FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"' SKIP_HEADER = 1);
âœ… NDJSON Upload to Snowflake

Table Created:

sql
Copy
Edit
CREATE OR REPLACE TABLE json_data_fda (
  raw_json VARIANT
);
File Format: NDJSON (1 JSON object per line)

Loaded using:

sql
Copy
Edit
COPY INTO json_data_fda
FROM @drug_stage/fda.json
FILE_FORMAT = (TYPE = 'JSON');
ğŸ›  Python Automation (pipeline.py)
Feature	Description
ğŸ”— Snowflake Connector	Uses snowflake-connector-python for ingestion
ğŸ—ƒ File Validation	Checks schema and format before upload
ğŸš€ Upload & Load Automation	Automates PUT & COPY INTO Snowflake stage
ğŸ§¾ Logging	Logs success/failure and errors for each run

ğŸ”§ dbt Work
âœ… Project Setup

Initialized using: dbt init health_integration_dbt

Configured Snowflake connection in profiles.yml

âœ… Source Definitions

Defined in: sources.yml

Example:

yaml
Copy
Edit
sources:
  - name: raw
    database: HEALTHCARE
    schema: DRUG_LISTINGS
    tables:
      - name: drug_listing_fda
âœ… Staging Model: stg_drug_listing_fda.sql

sql
Copy
Edit
SELECT
  report_id,
  report_date::DATE AS report_date,
  country,
  drug_name,
  patient_age::INT AS patient_age,
  patient_sex,
  side_effects
FROM {{ source('raw', 'drug_listing_fda') }}
ğŸ”œ Next Steps

Create marts models for:

Side effects by drug

Report count by region/time

Add schema tests and documentation

Build snapshots to track updates over time

Integrate dbt Cloud or Airflow for scheduling

ğŸ“‚ Folder Structure
bash
Copy
Edit
health-integration-project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ fda_cleaned.csv         # Cleaned CSV data
â”‚       â””â”€â”€ fda.json                # NDJSON-formatted JSON reports
â”‚
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ marts/                  # Future models
â”‚   â”œâ”€â”€ snapshots/                  # Future snapshots
â”‚   â””â”€â”€ dbt_project.yml
â”‚
â”œâ”€â”€ pipeline.py                     # Python ingestion & upload script
â””â”€â”€ README.md                       # Project documentation
âœ… Project Timeline & Progress
Week	Focus Area	Status
1	CSV/JSON Ingestion + Snowflake Upload	âœ… Completed
2	Python Pipeline & Automation	âœ… Completed
3	dbt Staging + Source Models	âœ… In Progress
4	dbt Marts + Snapshots + Dashboarding	â³ Upcoming
5	Airflow Scheduling + Visual Demos	âŒ Not Started

ğŸ“¸ Screenshots & Demo (Coming Soon)
Dashboard screenshots and model preview snapshots will be shared once the marts and visualization layers are finalized.

ğŸ‘¨â€ğŸ’» Author
Rishabh Rawat â€“ Passionate about real-world healthcare data engineering using Snowflake, Python, and dbt.

GitHub: github.com/Rishabh1627rawat

LinkedIn: (Add your profile link)
